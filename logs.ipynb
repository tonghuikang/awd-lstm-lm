{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attrs==19.1.0',\n",
       " 'backcall==0.1.0',\n",
       " 'bleach==3.1.0',\n",
       " 'decorator==4.4.0',\n",
       " 'defusedxml==0.6.0',\n",
       " 'entrypoints==0.3',\n",
       " 'ipykernel==5.1.1',\n",
       " 'ipython-genutils==0.2.0',\n",
       " 'ipython==7.5.0',\n",
       " 'ipywidgets==7.4.2',\n",
       " 'jedi==0.13.3',\n",
       " 'jinja2==2.10.1',\n",
       " 'jsonschema==3.0.1',\n",
       " 'jupyter-client==5.2.4',\n",
       " 'jupyter-console==6.0.0',\n",
       " 'jupyter-core==4.4.0',\n",
       " 'jupyter==1.0.0',\n",
       " 'markupsafe==1.1.1',\n",
       " 'mistune==0.8.4',\n",
       " 'nbconvert==5.5.0',\n",
       " 'nbformat==4.4.0',\n",
       " 'notebook==5.7.8',\n",
       " 'numpy==1.16.4',\n",
       " 'pandas==0.24.2',\n",
       " 'pandocfilters==1.4.2',\n",
       " 'parso==0.4.0',\n",
       " 'pexpect==4.7.0',\n",
       " 'pickleshare==0.7.5',\n",
       " 'pillow==6.0.0',\n",
       " 'prometheus-client==0.6.0',\n",
       " 'prompt-toolkit==2.0.9',\n",
       " 'ptyprocess==0.6.0',\n",
       " 'pygments==2.4.2',\n",
       " 'pyrsistent==0.15.2',\n",
       " 'python-dateutil==2.8.0',\n",
       " 'pytz==2019.1',\n",
       " 'pyzmq==18.0.1',\n",
       " 'qtconsole==4.5.1',\n",
       " 'send2trash==1.5.0',\n",
       " 'setuptools==41.0.1',\n",
       " 'six==1.12.0',\n",
       " 'terminado==0.8.2',\n",
       " 'testpath==0.4.2',\n",
       " 'torch==1.1.0',\n",
       " 'torchvision==0.3.0',\n",
       " 'tornado==6.0.2',\n",
       " 'traitlets==4.3.2',\n",
       " 'wcwidth==0.1.7',\n",
       " 'webencodings==0.5.1',\n",
       " 'widgetsnbextension==3.4.2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "# https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules\n",
    "sorted([\"%s==%s\" % (i.key, i.version) for i in pip.get_installed_distributions()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7f2372a6e208>\n",
      "1\n",
      "Tesla V100-SXM2-16GB\n",
      "True\n",
      "7501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing dataset...\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 100, in <module>\n",
      "    corpus = data.Corpus(args.data)\n",
      "  File \"/home/hkmac/awd-lstm-lm/data.py\", line 30, in __init__\n",
      "    self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
      "  File \"/home/hkmac/awd-lstm-lm/data.py\", line 40, in tokenize\n",
      "    for line in f:\n",
      "  File \"/usr/lib/python3.6/codecs.py\", line 321, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 2838: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "!python3 -u main.py --epochs 50 --nlayers 3 --emsize 400 --nhid 1840 --alpha 0 --beta 0 --dropoute 0 --dropouth 0.1 --dropouti 0.1 --dropout 0.4 --wdrop 0.2 --wdecay 1.2e-6 --bptt 200 --batch_size 128 --optimizer adam --lr 1e-3 --data data/enwik8 --save ENWIK8.pt --when 25 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset...\n",
      "Applying weight drop of 0.5 to weight_hh_l0\n",
      "Applying weight drop of 0.5 to weight_hh_l0\n",
      "Applying weight drop of 0.5 to weight_hh_l0\n",
      "[WeightDrop(\n",
      "  (module): LSTM(200, 1000)\n",
      "), WeightDrop(\n",
      "  (module): LSTM(1000, 1000)\n",
      "), WeightDrop(\n",
      "  (module): LSTM(1000, 200)\n",
      ")]\n",
      "Using []\n",
      "Args: Namespace(alpha=0.0, batch_size=128, beta=0.0, bptt=150, clip=0.25, cuda=True, data='data/pennchar', dropout=0.1, dropoute=0.0, dropouth=0.25, dropouti=0.1, emsize=200, epochs=500, log_interval=200, lr=0.002, model='LSTM', nhid=1000, nlayers=3, nonmono=5, optimizer='adam', resume='', save='PTBC.pt', seed=1111, tied=True, wdecay=1.2e-06, wdrop=0.5, when=[300, 400])\n",
      "Model total parameters: 13787650\n",
      "/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:522: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "| epoch   1 |   200/  261 batches | lr 0.00200 | ms/batch 162.74 | loss  2.98 | ppl    19.62 | bpc    4.294\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 49.75s | valid loss  2.14 | valid ppl     8.52 | valid bpc    3.091\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving model (new best validation)\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 240, in <module>\n",
      "    train()\n",
      "  File \"main.py\", line 196, in train\n",
      "    output, hidden, rnn_hs, dropped_rnn_hs = model(data, hidden, return_h=True)\n",
      "  File \"/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hkmac/awd-lstm-lm/model.py\", line 81, in forward\n",
      "    raw_output, new_h = rnn(raw_output, hidden[l])\n",
      "  File \"/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hkmac/awd-lstm-lm/weight_drop.py\", line 46, in forward\n",
      "    self._setweights()\n",
      "  File \"/home/hkmac/awd-lstm-lm/weight_drop.py\", line 43, in _setweights\n",
      "    setattr(self.module, name_w, w)\n",
      "  File \"/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 558, in __setattr__\n",
      "    .format(torch.typename(value), name))\n",
      "TypeError: cannot assign 'torch.cuda.FloatTensor' as parameter 'weight_hh_l0' (torch.nn.Parameter or None expected)\n"
     ]
    }
   ],
   "source": [
    "!python3 -u main.py --epochs 500 --nlayers 3 --emsize 200 --nhid 1000 --alpha 0 --beta 0 --dropoute 0 --dropouth 0.25 --dropouti 0.1 --dropout 0.1 --wdrop 0.5 --wdecay 1.2e-6 --bptt 150 --batch_size 128 --optimizer adam --lr 2e-3 --data data/pennchar --save PTBC.pt --when 300 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
