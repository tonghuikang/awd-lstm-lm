{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENWIK8.pt\t\t\t\t      generate.py\r\n",
      "LICENSE\t\t\t\t\t      getdata.sh\r\n",
      "PTBC.pt\t\t\t\t\t      locked_dropout.py\r\n",
      "PTBC.pt.e300\t\t\t\t      logs.ipynb\r\n",
      "PTBC.pt.e400\t\t\t\t      main.py\r\n",
      "README.md\t\t\t\t      model.py\r\n",
      "__pycache__\t\t\t\t      nohup.out\r\n",
      "corpus.5fe0e8525c745b4a450533184c69e47e.data  pointer.py\r\n",
      "corpus.e4b3ed728d0b973ba43f49cb1e1d45f6.data  save\r\n",
      "data\t\t\t\t\t      splitcross.py\r\n",
      "data.py\t\t\t\t\t      utils.py\r\n",
      "embed_regularize.py\t\t\t      weight_drop.py\r\n",
      "finetune.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attrs==19.1.0',\n",
       " 'backcall==0.1.0',\n",
       " 'bleach==3.1.0',\n",
       " 'decorator==4.4.0',\n",
       " 'defusedxml==0.6.0',\n",
       " 'entrypoints==0.3',\n",
       " 'ipykernel==5.1.1',\n",
       " 'ipython-genutils==0.2.0',\n",
       " 'ipython==7.5.0',\n",
       " 'ipywidgets==7.4.2',\n",
       " 'jedi==0.13.3',\n",
       " 'jinja2==2.10.1',\n",
       " 'jsonschema==3.0.1',\n",
       " 'jupyter-client==5.2.4',\n",
       " 'jupyter-console==6.0.0',\n",
       " 'jupyter-core==4.4.0',\n",
       " 'jupyter==1.0.0',\n",
       " 'markupsafe==1.1.1',\n",
       " 'mistune==0.8.4',\n",
       " 'nbconvert==5.5.0',\n",
       " 'nbformat==4.4.0',\n",
       " 'notebook==5.7.8',\n",
       " 'numpy==1.16.4',\n",
       " 'pandas==0.24.2',\n",
       " 'pandocfilters==1.4.2',\n",
       " 'parso==0.4.0',\n",
       " 'pexpect==4.7.0',\n",
       " 'pickleshare==0.7.5',\n",
       " 'pillow==6.0.0',\n",
       " 'prometheus-client==0.6.0',\n",
       " 'prompt-toolkit==2.0.9',\n",
       " 'ptyprocess==0.6.0',\n",
       " 'pygments==2.4.2',\n",
       " 'pyrsistent==0.15.2',\n",
       " 'python-dateutil==2.8.0',\n",
       " 'pytz==2019.1',\n",
       " 'pyzmq==18.0.1',\n",
       " 'qtconsole==4.5.1',\n",
       " 'send2trash==1.5.0',\n",
       " 'setuptools==41.0.1',\n",
       " 'six==1.12.0',\n",
       " 'terminado==0.8.2',\n",
       " 'testpath==0.4.2',\n",
       " 'torch==1.1.0',\n",
       " 'torchvision==0.3.0',\n",
       " 'tornado==6.0.2',\n",
       " 'traitlets==4.3.2',\n",
       " 'wcwidth==0.1.7',\n",
       " 'webencodings==0.5.1',\n",
       " 'widgetsnbextension==3.4.2']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "# https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules\n",
    "sorted([\"%s==%s\" % (i.key, i.version) for i in pip.get_installed_distributions()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7f0da0722898>\n",
      "1\n",
      "Tesla V100-SXM2-16GB\n",
      "True\n",
      "7501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset...\n",
      "Applying weight drop of 0.2 to weight_hh_l0\n",
      "Applying weight drop of 0.2 to weight_hh_l0\n",
      "Applying weight drop of 0.2 to weight_hh_l0\n",
      "[WeightDrop(\n",
      "  (module): LSTM(400, 1840)\n",
      "), WeightDrop(\n",
      "  (module): LSTM(1840, 1840)\n",
      "), WeightDrop(\n",
      "  (module): LSTM(1840, 400)\n",
      ")]\n",
      "Resuming model ...\n",
      "Args: Namespace(alpha=0.0, batch_size=128, beta=0.0, bptt=200, clip=0.25, cuda=True, data='data/enwik8', dropout=0.4, dropoute=0.0, dropouth=0.1, dropouti=0.1, emsize=400, epochs=50, log_interval=200, lr=0.001, model='LSTM', nhid=1840, nlayers=3, nonmono=5, optimizer='adam', resume='ENWIK8.pt', save='ENWIK8.pt', seed=1111, tied=True, wdecay=1.2e-06, wdrop=0.2, when=[25, 35])\n",
      "Model total parameters: 74993241\n",
      "/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:522: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "| epoch   1 |   200/ 3039 batches | lr 0.00100 | ms/batch 646.93 | loss  1.58 | ppl     4.84 | bpc    2.276\n",
      "| epoch   1 |   400/ 3039 batches | lr 0.00100 | ms/batch 630.94 | loss  1.56 | ppl     4.78 | bpc    2.258\n",
      "| epoch   1 |   600/ 3039 batches | lr 0.00100 | ms/batch 635.40 | loss  1.56 | ppl     4.77 | bpc    2.253\n",
      "| epoch   1 |   800/ 3039 batches | lr 0.00100 | ms/batch 633.53 | loss  1.55 | ppl     4.73 | bpc    2.240\n",
      "| epoch   1 |  1000/ 3039 batches | lr 0.00100 | ms/batch 634.33 | loss  1.55 | ppl     4.73 | bpc    2.242\n",
      "| epoch   1 |  1200/ 3039 batches | lr 0.00100 | ms/batch 639.80 | loss  1.55 | ppl     4.72 | bpc    2.240\n",
      "| epoch   1 |  1400/ 3039 batches | lr 0.00100 | ms/batch 640.26 | loss  1.54 | ppl     4.65 | bpc    2.218\n",
      "| epoch   1 |  1600/ 3039 batches | lr 0.00100 | ms/batch 638.39 | loss  1.53 | ppl     4.62 | bpc    2.209\n",
      "| epoch   1 |  1800/ 3039 batches | lr 0.00100 | ms/batch 632.93 | loss  1.50 | ppl     4.47 | bpc    2.160\n",
      "^C\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "!python3 -u main.py --epochs 50 --nlayers 3 --emsize 400 --nhid 1840 --alpha 0 --beta 0 --dropoute 0 --dropouth 0.1 --dropouti 0.1 --dropout 0.4 --wdrop 0.2 --wdecay 1.2e-6 --bptt 200 --batch_size 128 --optimizer adam --lr 1e-3 --data data/enwik8 --save ENWIK8.pt --resume ENWIK8.pt --when 25 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 -u main.py --epochs 500 --nlayers 3 --emsize 200 --nhid 1000 --alpha 0 --beta 0 --dropoute 0 --dropouth 0.25 --dropouti 0.1 --dropout 0.1 --wdrop 0.5 --wdecay 1.2e-6 --bptt 150 --batch_size 128 --optimizer adam --lr 2e-3 --data data/pennchar --save PTBC.pt --resume PTBC.pt --when 300 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 weight_drop.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate.py:63: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  input = Variable(torch.rand(1, 1).mul(ntokens).long(), volatile=True)\r\n",
      "/home/hkmac/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:522: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\r\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"generate.py\", line 73, in <module>\r\n",
      "    word = corpus.dictionary.idx2word[word_idx]\r\n",
      "IndexError: list index out of range\r\n"
     ]
    }
   ],
   "source": [
    "!python3 generate.py --model LSTM --cuda --data data/pennchar --checkpoint PTBC.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 generate.py --model LSTM --cuda --data data/enwik8 --checkpoint ENWIK8.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
